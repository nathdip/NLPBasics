{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is VERB aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x1f81c7fc518>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x1f81ca2d048>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x1f81ca2d0a0>)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Tesla isn't looking into startups anymore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla      PROPN      nsubj     \n",
      "is         VERB       aux       \n",
      "n't        ADV        neg       \n",
      "looking    VERB       ROOT      \n",
      "into       ADP        prep      \n",
      "startups   NOUN       pobj      \n",
      "anymore    ADV        advmod    \n",
      ".          PUNCT      punct     \n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(f\"{token.text:10} {token.pos_:10} {token.dep_:10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'The primary Muslim litigant in the title dispute case has informed the Supreme Court that it is willing to drop its appeals in the matter – and its claims to the land on which the historic Babri Masjid stood for centuries before it was demolished by Hindutva activists and leaders in 1992 – provided the Centre is willing to guarantee that all other places of worship in India will be protected from \"similar encroachment\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The        DET        det       \n",
      "primary    ADJ        amod      \n",
      "Muslim     ADJ        amod      \n",
      "litigant   NOUN       nsubj     \n",
      "in         ADP        prep      \n",
      "the        DET        det       \n",
      "title      NOUN       compound  \n",
      "dispute    NOUN       compound  \n",
      "case       NOUN       pobj      \n",
      "has        VERB       aux       \n",
      "informed   VERB       ROOT      \n",
      "the        DET        det       \n",
      "Supreme    PROPN      compound  \n",
      "Court      PROPN      dobj      \n",
      "that       ADP        mark      \n",
      "it         PRON       nsubj     \n",
      "is         VERB       ccomp     \n",
      "willing    ADJ        acomp     \n",
      "to         PART       aux       \n",
      "drop       VERB       xcomp     \n",
      "its        ADJ        poss      \n",
      "appeals    NOUN       dobj      \n",
      "in         ADP        prep      \n",
      "the        DET        det       \n",
      "matter     NOUN       pobj      \n",
      "–          PUNCT      punct     \n",
      "and        CCONJ      cc        \n",
      "its        ADJ        poss      \n",
      "claims     NOUN       conj      \n",
      "to         ADP        prep      \n",
      "the        DET        det       \n",
      "land       NOUN       pobj      \n",
      "on         ADP        prep      \n",
      "which      ADJ        pobj      \n",
      "the        DET        det       \n",
      "historic   ADJ        amod      \n",
      "Babri      PROPN      compound  \n",
      "Masjid     PROPN      nsubj     \n",
      "stood      VERB       relcl     \n",
      "for        ADP        prep      \n",
      "centuries  NOUN       pobj      \n",
      "before     ADP        mark      \n",
      "it         PRON       nsubjpass \n",
      "was        VERB       auxpass   \n",
      "demolished VERB       advcl     \n",
      "by         ADP        agent     \n",
      "Hindutva   PROPN      compound  \n",
      "activists  NOUN       pobj      \n",
      "and        CCONJ      cc        \n",
      "leaders    NOUN       conj      \n",
      "in         ADP        prep      \n",
      "1992       NUM        pobj      \n",
      "–          PUNCT      punct     \n",
      "provided   VERB       acl       \n",
      "the        DET        det       \n",
      "Centre     PROPN      nsubj     \n",
      "is         VERB       conj      \n",
      "willing    ADJ        acomp     \n",
      "to         PART       aux       \n",
      "guarantee  VERB       xcomp     \n",
      "that       ADP        mark      \n",
      "all        DET        det       \n",
      "other      ADJ        amod      \n",
      "places     NOUN       nsubjpass \n",
      "of         ADP        prep      \n",
      "worship    NOUN       pobj      \n",
      "in         ADP        prep      \n",
      "India      PROPN      pobj      \n",
      "will       VERB       aux       \n",
      "be         VERB       auxpass   \n",
      "protected  VERB       ccomp     \n",
      "from       ADP        prep      \n",
      "\"          PUNCT      punct     \n",
      "similar    ADJ        amod      \n",
      "encroachment NOUN       pobj      \n",
      "\"          PUNCT      punct     \n",
      ".          PUNCT      punct     \n"
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "    print(f\"{token.text:10} {token.pos_:10} {token.dep_:10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = doc3[72:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'This is the first sentence. This is the second sentence. This is the third sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is the second sentence.\n",
      "This is the third sentence\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc4.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[12].is_sent_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens are the basic building blocks of a doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
